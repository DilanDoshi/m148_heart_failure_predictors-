{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be71f7cc",
   "metadata": {},
   "source": [
    "# Neural Networks with PyTorch\n",
    "Note: This notebook will be used for nn as an educational extension and will compare its performance. For this dataset, since it is small and tabular, a tree-based model may be more appropriate.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1253fc4",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "Since our dataset is small, from research we have determined that a smal feed-forward MLP would be a good candidate.  \n",
    "\n",
    "A shallow MLP gives a flexible nonlinear decision boundary (via ReLU) while keeping cariance controlled through small width, dropout/L2, and early stopping.  \n",
    "\n",
    "Moreover, MLPs learn smooth functions and with standardized tabular inputs, this may be beneficial.  \n",
    "\n",
    "A compact MLP will introduce enough nonlinearity to model interactiosn in the 12 clinical features but keep capacity, variance, and training instability in check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ecf067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f94d4dc",
   "metadata": {},
   "source": [
    "## Data Preparation and Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24204971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 179 samples\n",
      "Validation set: 45 samples\n",
      "Class distribution in training: [130  49]\n",
      "Class distribution in validation: [33 12]\n"
     ]
    }
   ],
   "source": [
    "# Load data - splits were created in previous notebook \n",
    "X_train = pd.read_csv(\"../data/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\").values.ravel()  # Convert to 1D array\n",
    "\n",
    "X_val = pd.read_csv(\"../data/X_val.csv\")\n",
    "y_val = pd.read_csv(\"../data/y_val.csv\").values.ravel()  # Convert to 1D array\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Class distribution in training: {np.bincount(y_train)}\")\n",
    "print(f\"Class distribution in validation: {np.bincount(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1fd0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']\n",
    "categorical_features = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "000a74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transformer + Pipeline to standardize data \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_features),\n",
    "        ('cat', 'passthrough', categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb6ac078",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849de2db",
   "metadata": {},
   "source": [
    "## PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eb3eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train Tensors\n",
    "X_train_tensor = torch.tensor(X_train_processed, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Validation Tensors\n",
    "X_val_tensor = torch.tensor(X_val_processed, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # shuffle=True prevents model from seeign data in the same order every time,\n",
    "                                                                      # reducing correlation between successive batches and improving stochastic optimization.\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca2dd2",
   "metadata": {},
   "source": [
    "## Create Torch model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076c894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
